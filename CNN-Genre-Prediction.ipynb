{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0533b4e7",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "End-to-end TensorFlow pipeline for multilabel tag classification from spectrogram JPGs.\n",
    "Assumptions:\n",
    "- You have a CSV with columns: musicbrainz_recording_id, artist, track, album, musicbrainz_artist, final_tags\n",
    "- Each spectrogram image is named <musicbrainz_recording_id>.jpg in an images/ folder (or point to your directory)\n",
    "- There are 8 possible tags (the script will compute unique tags and assert that length == 8)\n",
    "\n",
    "\n",
    "What this file provides:\n",
    "1. CSV + filesystem intersection: keep only common ids\n",
    "2. Parser for final_tags column (robust to quotes/encoding)\n",
    "3. Build tf.data.Dataset reading JPEGs, preprocessing, augmentation\n",
    "4. CNN model definition (Keras) for multilabel classification -> sigmoid outputs for each tag\n",
    "5. Training, validation split, callbacks, saving\n",
    "6. Inference functions that return probabilities per tag\n",
    "\n",
    "\n",
    "Run: adjust paths and hyperparameters near the top of the file.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f70001e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45c5a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- USER CONFIG -------------------------------\n",
    "CSV_PATH = \"data/tracks_metadata_202510071738.csv\" # path to your CSV\n",
    "IMAGE_DIR = \"data/spectrogram/\" # directory containing <mbid>.jpg\n",
    "IMAGE_EXT = \".jpg\" # image file extension\n",
    "IMAGE_SIZE = (250, 100) # model input size\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "EPOCHS = 40\n",
    "SEED = 42\n",
    "MODEL_OUTPUT = \"models/spectrogram_multilabel.h5\"\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe49fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ UTIL FUNCTIONS -----------------------------\n",
    "\n",
    "\n",
    "def read_csv_and_filter(csv_path: str, image_dir: str, id_col: str = \"musicbrainz_recording_id\") -> pd.DataFrame:\n",
    "    \"\"\"Read CSV, parse tags column, and retain only rows with a matching image file present.\n",
    "    Returns a cleaned DataFrame with an added column 'image_path'.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, usecols=[\"musicbrainz_recording_id\", \"final_tags\"])\n",
    "\n",
    "\n",
    "    if id_col not in df.columns:\n",
    "        raise ValueError(f\"CSV must contain column '{id_col}'. Found: {df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "    # robust parser for final_tags column\n",
    "    if 'final_tags' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'final_tags' column\")\n",
    "\n",
    "\n",
    "    def parse_final_tags_cell(cell):\n",
    "    # cell examples: '[\"pop\", \"blues-r&b-soul\"]' or \"['pop','rock']\"\n",
    "        if pd.isna(cell):\n",
    "            return []\n",
    "        if isinstance(cell, (list, tuple)):\n",
    "            return list(cell)\n",
    "        s = str(cell)\n",
    "        # Try: ast.literal_eval (safe) first\n",
    "        try:\n",
    "            parsed = ast.literal_eval(s)\n",
    "            if isinstance(parsed, (list, tuple)):\n",
    "                return [str(x).strip() for x in parsed]\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Fallback: try to strip brackets and split by comma\n",
    "        s2 = s.strip().lstrip('[').rstrip(']')\n",
    "        parts = [p.strip().strip('\\\"').strip(\"'\") for p in s2.split(',') if p.strip()]\n",
    "        return parts\n",
    "\n",
    "\n",
    "    df['parsed_tags'] = df['final_tags'].apply(parse_final_tags_cell)\n",
    "\n",
    "\n",
    "    # build image path\n",
    "    def image_path_for_id(mbid):\n",
    "        return os.path.join(image_dir, f\"{mbid}{IMAGE_EXT}\")\n",
    "\n",
    "\n",
    "    df['image_path'] = df[id_col].apply(image_path_for_id)\n",
    "    # check existence\n",
    "    df['image_exists'] = df['image_path'].apply(os.path.exists)\n",
    "\n",
    "\n",
    "    # keep only existing\n",
    "    filtered = df[df['image_exists']].copy()\n",
    "    filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    total_csv = len(df)\n",
    "    total_images = sum(1 for _ in Path(image_dir).glob(f'*{IMAGE_EXT}'))\n",
    "    kept = len(filtered)\n",
    "    print(f\"CSV rows: {total_csv}, images in folder: {total_images}, kept after intersection: {kept}\")\n",
    "\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7578475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/spectrogram/'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29a300a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV rows: 1096, images in folder: 1083, kept after intersection: 1083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>musicbrainz_recording_id</th>\n",
       "      <th>final_tags</th>\n",
       "      <th>parsed_tags</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>35181f72-868e-4298-b516-ac6c4c75652f</td>\n",
       "      <td>[\"pop\"]</td>\n",
       "      <td>[pop]</td>\n",
       "      <td>data/spectrogram/35181f72-868e-4298-b516-ac6c4...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>15e2fda3-b76a-4d7d-94a9-a429d336352f</td>\n",
       "      <td>[\"rock-metal-psychedelic\"]</td>\n",
       "      <td>[rock-metal-psychedelic]</td>\n",
       "      <td>data/spectrogram/15e2fda3-b76a-4d7d-94a9-a429d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>838db018-12ee-4d53-828f-304769f1933d</td>\n",
       "      <td>[\"hip_hop-rap\"]</td>\n",
       "      <td>[hip_hop-rap]</td>\n",
       "      <td>data/spectrogram/838db018-12ee-4d53-828f-30476...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>8079d38b-efcf-401e-817c-cb4f293c2e89</td>\n",
       "      <td>[\"rock-metal-psychedelic\", \"pop\", \"blues-r&amp;b-s...</td>\n",
       "      <td>[rock-metal-psychedelic, pop, blues-r&amp;b-soul, ...</td>\n",
       "      <td>data/spectrogram/8079d38b-efcf-401e-817c-cb4f2...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>815ac72b-5477-421c-a685-8008886af46f</td>\n",
       "      <td>[\"pop\", \"rock-metal-psychedelic\"]</td>\n",
       "      <td>[pop, rock-metal-psychedelic]</td>\n",
       "      <td>data/spectrogram/815ac72b-5477-421c-a685-80088...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 musicbrainz_recording_id  \\\n",
       "195  35181f72-868e-4298-b516-ac6c4c75652f   \n",
       "52   15e2fda3-b76a-4d7d-94a9-a429d336352f   \n",
       "530  838db018-12ee-4d53-828f-304769f1933d   \n",
       "872  8079d38b-efcf-401e-817c-cb4f293c2e89   \n",
       "523  815ac72b-5477-421c-a685-8008886af46f   \n",
       "\n",
       "                                            final_tags  \\\n",
       "195                                            [\"pop\"]   \n",
       "52                          [\"rock-metal-psychedelic\"]   \n",
       "530                                    [\"hip_hop-rap\"]   \n",
       "872  [\"rock-metal-psychedelic\", \"pop\", \"blues-r&b-s...   \n",
       "523                  [\"pop\", \"rock-metal-psychedelic\"]   \n",
       "\n",
       "                                           parsed_tags  \\\n",
       "195                                              [pop]   \n",
       "52                            [rock-metal-psychedelic]   \n",
       "530                                      [hip_hop-rap]   \n",
       "872  [rock-metal-psychedelic, pop, blues-r&b-soul, ...   \n",
       "523                      [pop, rock-metal-psychedelic]   \n",
       "\n",
       "                                            image_path  image_exists  \n",
       "195  data/spectrogram/35181f72-868e-4298-b516-ac6c4...          True  \n",
       "52   data/spectrogram/15e2fda3-b76a-4d7d-94a9-a429d...          True  \n",
       "530  data/spectrogram/838db018-12ee-4d53-828f-30476...          True  \n",
       "872  data/spectrogram/8079d38b-efcf-401e-817c-cb4f2...          True  \n",
       "523  data/spectrogram/815ac72b-5477-421c-a685-80088...          True  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv_and_filter(CSV_PATH, IMAGE_DIR)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52ff6cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.iloc[805].parsed_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8296378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tag_binarizer(df: pd.DataFrame, tag_col: str = 'parsed_tags', expected_n_tags: int = None) -> Tuple[MultiLabelBinarizer, List[str]]:\n",
    "    \"\"\"Create a MultiLabelBinarizer mapping.\n",
    "    If expected_n_tags provided, assert number of unique tags equals that value.\n",
    "    \"\"\"\n",
    "    mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "    mlb.fit(df[tag_col])\n",
    "    classes = list(mlb.classes_)\n",
    "    print(f\"Found {len(classes)} unique tags: {classes}\")\n",
    "    if expected_n_tags is not None:\n",
    "        assert len(classes) == expected_n_tags, f\"Expected {expected_n_tags} tags but found {len(classes)}\"\n",
    "    return mlb, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76618c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 unique tags: ['blues-r&b-soul', 'electronic-funk-disco-dance', 'folk-classical-country-jazz', 'hip_hop-rap', 'opera-musical-theater-soundtrack-vocal-a_cappella', 'others', 'pop', 'rock-metal-psychedelic']\n"
     ]
    }
   ],
   "source": [
    "mlb, classes = build_tag_binarizer(df, tag_col='parsed_tags', expected_n_tags=None) # set to 8 if you want hard assert\n",
    "n_labels = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b371ba97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['blues-r&b-soul',\n",
       "  'electronic-funk-disco-dance',\n",
       "  'folk-classical-country-jazz',\n",
       "  'hip_hop-rap',\n",
       "  'opera-musical-theater-soundtrack-vocal-a_cappella',\n",
       "  'others',\n",
       "  'pop',\n",
       "  'rock-metal-psychedelic'],\n",
       " 8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes, n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3eca5d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binarize labels\n",
    "labels = mlb.transform(df['parsed_tags'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb85a8",
   "metadata": {},
   "source": [
    "#### TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34e94923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/val/test split\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    df['image_path'].tolist(), labels, test_size=0.15, random_state=SEED, stratify=None\n",
    "    )\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_paths, train_labels, test_size=0.15, random_state=SEED, stratify=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dbb804c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['data/spectrogram/ca1f8b74-6976-42b0-a415-1f2934a752cd.jpg',\n",
       "  'data/spectrogram/eb623fb9-ed07-4f13-a8aa-446f014c5fee.jpg',\n",
       "  'data/spectrogram/036892d0-355c-4436-bb06-47e9f235e4b2.jpg',\n",
       "  'data/spectrogram/39973f6c-4d2f-4683-947c-10f74f909cfe.jpg',\n",
       "  'data/spectrogram/e838057c-04e2-4875-94e7-75a74123cbe9.jpg'],\n",
       " array([[1, 0, 1, 0, 0, 0, 1, 1],\n",
       "        [0, 0, 1, 0, 0, 0, 1, 0],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 1, 0]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths[:5], train_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5babe7e",
   "metadata": {},
   "source": [
    "#### Tensorflow compatible dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd7c68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- TENSORFLOW DATA PIPELINE -----------------------\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(path: tf.Tensor, label: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"Given a filename and label, read image and process to [0,1] float32 tensor.\"\"\"\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=1) # spectrograms are RGB or grayscale saved as RGB\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def augment_image(image: tf.Tensor, label: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    # Simple augmentations suitable for spectrograms: small vertical/horizontal shifts, random brightness\n",
    "    # Be conservative: don't flip horizontally (would flip time axis)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.08)\n",
    "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    # small time/frequency shifts -> translate horizontally/vertically\n",
    "    if tf.random.uniform(()) > 0.7:\n",
    "    # width, height translation\n",
    "        image = tf.roll(image, shift=tf.random.uniform((), -10, 10, dtype=tf.int32), axis=1)\n",
    "        if tf.random.uniform(()) > 0.7:\n",
    "            image = tf.roll(image, shift=tf.random.uniform((), -5, 5, dtype=tf.int32), axis=0)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_tf_dataset(paths: List[str], labels: np.ndarray, training: bool = True) -> tf.data.Dataset:\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(paths), seed=SEED)\n",
    "    ds = ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.map(augment_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "511e142d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 250, 100, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 8), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = make_tf_dataset(train_paths, np.array(train_labels), training=True)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51407303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_ds = make_tf_dataset(val_paths, np.array(val_labels), training=False)\n",
    "test_ds = make_tf_dataset(test_paths, np.array(test_labels), training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1298d137",
   "metadata": {},
   "source": [
    "#### BUILD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45477612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape=(224,224,3), n_labels=8, dropout_rate=0.5) -> tf.keras.Model:\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    # Simple bespoke CNN - replace or expand with EfficientNet, MobileNetV2, etc. for better performance\n",
    "    x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool2D(2)(x)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool2D(2)(x)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool2D(2)(x)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(n_labels, activation='sigmoid')(x) # multilabel -> sigmoid\n",
    "\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c9fbc973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m2,056\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">459,208</span> (1.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m459,208\u001b[0m (1.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">457,736</span> (1.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m457,736\u001b[0m (1.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> (5.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,472\u001b[0m (5.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model(input_shape=(*IMAGE_SIZE, 3), n_labels=n_labels)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad9c058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_train(model: tf.keras.Model,\n",
    "    train_ds: tf.data.Dataset,\n",
    "    val_ds: tf.data.Dataset,\n",
    "    epochs: int = EPOCHS,\n",
    "    model_output: str = MODEL_OUTPUT):\n",
    "\n",
    "\n",
    "    # Ensure the checkpoint directory exists before training\n",
    "    model_dir = os.path.dirname(model_output)\n",
    "    if model_dir:\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(model_output, monitor='val_loss', save_best_only=True)\n",
    "    ]\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.AUC(curve='ROC', multi_label=True), 'binary_accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks)\n",
    "    return history\n",
    "\n",
    "\n",
    "# ------------------------------ INFERENCE ---------------------------------\n",
    "\n",
    "\n",
    "def predict_probabilities(model: tf.keras.Model, image_paths: List[str], mlb: MultiLabelBinarizer) -> List[Dict[str, float]]:\n",
    "    paths = tf.constant(image_paths)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    def _load(path):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, IMAGE_SIZE)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        return img\n",
    "    ds = ds.map(lambda p: _load(p)).batch(BATCH_SIZE)\n",
    "    preds = model.predict(ds)\n",
    "    results = []\n",
    "    for row in preds:\n",
    "        mapping = {label: float(prob) for label, prob in zip(mlb.classes_, row)}\n",
    "        results.append(mapping)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa292ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - auc_2: 0.5107 - binary_accuracy: 0.5053 - loss: 0.9102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 800ms/step - auc_2: 0.5096 - binary_accuracy: 0.5115 - loss: 0.9066 - val_auc_2: 0.4751 - val_binary_accuracy: 0.5571 - val_loss: 0.6838 - learning_rate: 1.0000e-04\n",
      "Epoch 2/40\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - auc_2: 0.5539 - binary_accuracy: 0.5466 - loss: 0.8557"
     ]
    }
   ],
   "source": [
    "history = compile_and_train(model, train_ds, val_ds, epochs=EPOCHS, model_output=MODEL_OUTPUT)\n",
    "\n",
    "\n",
    "# Evaluate on test set\n",
    "print('\\nEvaluating on test set...')\n",
    "res = model.evaluate(test_ds)\n",
    "print(res)\n",
    "\n",
    "\n",
    "# Save class mapping\n",
    "out_dir = os.path.dirname(MODEL_OUTPUT)\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "with open(os.path.join(out_dir, 'classes.json'), 'w') as f:\n",
    "    json.dump({'classes': classes}, f)\n",
    "\n",
    "\n",
    "print(f\"Model saved to {MODEL_OUTPUT} and classes saved to {os.path.join(out_dir, 'classes.json')}\")\n",
    "\n",
    "\n",
    "# Example inference usage (first 5 test images)\n",
    "sample_paths = test_paths[:5]\n",
    "probs = predict_probabilities(model, sample_paths, mlb)\n",
    "for p, path in zip(probs, sample_paths):\n",
    "    print(path, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8555545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --------------------------- NOTES & TIPS ---------------------------------\n",
    "# - If you have imbalanced labels, consider computing per-class positive weights and using a custom weighted loss.\n",
    "# - For better accuracy, replace the backbone with a pretrained model (EfficientNetB0, MobileNetV2) and fine-tune.\n",
    "# Example: use tf.keras.applications.EfficientNetB0(include_top=False, input_shape=..., weights='imagenet') then add GAP + Dense(sigmoid).\n",
    "# - If your spectrograms are mono grayscale, you can decode as channels=1 and optionally repeat channels to 3 for ImageNet backbones.\n",
    "# - Tune augmentations carefully; some augmentations (horizontal flip) may break time-frequency relationships and are not recommended.\n",
    "# - To use class weights: compute pos_weight = (N - pos) / pos per class and use them in a custom loss.\n",
    "# -------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
